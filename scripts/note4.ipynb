{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import sklearn\n",
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация глобальных переменных, а также наборов данных, таких как стоп-слова и знаки пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NitghtWay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NitghtWay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "rus = \"russian\"\n",
    "sw = stopwords.words(rus)\n",
    "morph = MorphAnalyzer()\n",
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(language=rus)\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализация пути до набора данных\n",
    "test_ds1_path = \"C:\\\\course_work\\\\feature_extraction_NLP\\\\data\\\\test_ds1\\\\train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>label</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>verb</th>\n",
       "      <th>negation</th>\n",
       "      <th>genre</th>\n",
       "      <th>idx</th>\n",
       "      <th>no_negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сумма ущерба составила одну тысячу рублей. Уто...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Ранее местный житель совершал подобное правона...</td>\n",
       "      <td>судить</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>kp</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Перебрасываясь словечками, они скользят глазам...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>Они что-то понимают</td>\n",
       "      <td>смотреть</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>— Разве что, — сказала она, — мы хотим где-ниб...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Это “ Таганская ”, а не “ Тульская ”.</td>\n",
       "      <td>понять</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зима, наконец, показала свой характер.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>У зимы есть свой характер.</td>\n",
       "      <td>показать</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>kp</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ГуманностьБогаподобнымсценариемнепредполагаетс...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>Это должно быть просто.</td>\n",
       "      <td>сказать</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Тверские спортсмены показали отличный результа...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>У тверских спортсменов пять новых медалей.</td>\n",
       "      <td>суметь</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>kp</td>\n",
       "      <td>433</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Просто я не хочу с ним жить и, извини, больше ...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>Этого было вполне достаточно.</td>\n",
       "      <td>уверять</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>434</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Второй аргумент: все читаем и видим, что надви...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Надвигается вторая волна кризиса.</td>\n",
       "      <td>видеть</td>\n",
       "      <td>negation</td>\n",
       "      <td>interfax</td>\n",
       "      <td>435</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>— Да, сын. Здравствуй. — Ты можешь говорить, н...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Сын не занят</td>\n",
       "      <td>говорить</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>436</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Там сказали, что сейчас принимаются меры по сп...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Сейчас принимаются меры по спуску тела умершег...</td>\n",
       "      <td>сказать</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>interfax</td>\n",
       "      <td>437</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               premise          label  \\\n",
       "0    Сумма ущерба составила одну тысячу рублей. Уто...     entailment   \n",
       "1    Перебрасываясь словечками, они скользят глазам...  contradiction   \n",
       "2    — Разве что, — сказала она, — мы хотим где-ниб...        neutral   \n",
       "3               Зима, наконец, показала свой характер.  contradiction   \n",
       "4    ГуманностьБогаподобнымсценариемнепредполагаетс...  contradiction   \n",
       "..                                                 ...            ...   \n",
       "433  Тверские спортсмены показали отличный результа...     entailment   \n",
       "434  Просто я не хочу с ним жить и, извини, больше ...  contradiction   \n",
       "435  Второй аргумент: все читаем и видим, что надви...        neutral   \n",
       "436  — Да, сын. Здравствуй. — Ты можешь говорить, н...        neutral   \n",
       "437  Там сказали, что сейчас принимаются меры по сп...     entailment   \n",
       "\n",
       "                                            hypothesis      verb     negation  \\\n",
       "0    Ранее местный житель совершал подобное правона...    судить  no_negation   \n",
       "1                                  Они что-то понимают  смотреть  no_negation   \n",
       "2                Это “ Таганская ”, а не “ Тульская ”.    понять  no_negation   \n",
       "3                           У зимы есть свой характер.  показать  no_negation   \n",
       "4                              Это должно быть просто.   сказать  no_negation   \n",
       "..                                                 ...       ...          ...   \n",
       "433         У тверских спортсменов пять новых медалей.    суметь  no_negation   \n",
       "434                      Этого было вполне достаточно.   уверять  no_negation   \n",
       "435                  Надвигается вторая волна кризиса.    видеть     negation   \n",
       "436                                       Сын не занят  говорить  no_negation   \n",
       "437  Сейчас принимаются меры по спуску тела умершег...   сказать  no_negation   \n",
       "\n",
       "        genre  idx no_negation  \n",
       "0          kp    0         NaN  \n",
       "1     fiction    1         NaN  \n",
       "2     fiction    2         NaN  \n",
       "3          kp    3         NaN  \n",
       "4     fiction    4         NaN  \n",
       "..        ...  ...         ...  \n",
       "433        kp  433         NaN  \n",
       "434   fiction  434         NaN  \n",
       "435  interfax  435         NaN  \n",
       "436   fiction  436         NaN  \n",
       "437  interfax  437         NaN  \n",
       "\n",
       "[438 rows x 8 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выгрузка данных с помощью Pandas, а также просмотр\n",
    "data = pd.read_json(test_ds1_path, lines=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kp', 'fiction', 'interfax'], dtype=object)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сумма ущерба составила одну тысячу рублей. Уто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Перебрасываясь словечками, они скользят глазам...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>— Разве что, — сказала она, — мы хотим где-ниб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зима, наконец, показала свой характер.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ГуманностьБогаподобнымсценариемнепредполагаетс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise\n",
       "0  Сумма ущерба составила одну тысячу рублей. Уто...\n",
       "1  Перебрасываясь словечками, они скользят глазам...\n",
       "2  — Разве что, — сказала она, — мы хотим где-ниб...\n",
       "3             Зима, наконец, показала свой характер.\n",
       "4  ГуманностьБогаподобнымсценариемнепредполагаетс..."
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Удаление не используемых столбцов\n",
    "data = data.drop(['label', 'hypothesis', 'verb','negation'\n",
    ",'genre','idx','no_negation'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для вывода текстовых данных в удобном формате\n",
    "def print_table(array):\n",
    "    table_width = 5\n",
    "    for i in range(0, len(array), table_width):\n",
    "        row = array[i:i + table_width]\n",
    "        formatted_row = \" \".join([\"{:<10}\".format(str(elem)) for elem in row])\n",
    "        print(formatted_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для удаления символов пунктуации\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([ch for ch in text if ch not in \n",
    "    string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для удаления чисел\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для удаления последовательностей\n",
    "def remove_patterns(text):\n",
    "    text = re.sub(patterns, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для удаления не буквенных символов\n",
    "def remove_notalpha(text):\n",
    "    return ''.join(i if i.isalpha() else ' ' for i in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминг с использованием Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ГуманностьБогаподобнымсценариемнепредполагается. Но Его благость остается в неприкосновенности. Непросто жить в таком мире, но кто сказал, что это должно быть просто?\n"
     ]
    }
   ],
   "source": [
    "example_text = data['premise'][4] #Текст для примера\n",
    "print(example_text) #Вывод текста для примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я токенизации с использованием Snowball\n",
    "def tokenize_snowball(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_patterns(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(snowball.stem(w))\n",
    "            \n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "но         ег         благост    оста       непрост   \n",
      "жит        так        мир        сказа      эт        \n",
      "должн      прост     \n"
     ]
    }
   ],
   "source": [
    "#Вывод результата с использованем ф-ии\n",
    "print_table(tokenize_snowball(example_text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминг с использованием алгоритма Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я токенизации с использованием Lancaster\n",
    "def tokenize_lancaster(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_patterns(text)\n",
    "    text = remove_punctuation(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(lancaster.stem(w))\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "но         его        благость   остается   непросто  \n",
      "жить       таком      мире       сказал     это       \n",
      "должно     просто    \n"
     ]
    }
   ],
   "source": [
    "#вывод примера\n",
    "print_table(tokenize_lancaster(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация с помощью PyMorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я токенизации с помощью PyMorphy2\n",
    "def tokenize_morphy(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_patterns(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(morph.normal_forms(w)[0])\n",
    "    if len(all_words) > 2:\n",
    "        return all_words\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "но         он         благость   оставаться непросто  \n",
      "жить       такой      мир        сказать    это       \n",
      "должный    просто    \n"
     ]
    }
   ],
   "source": [
    "#вывод примера\n",
    "print_table(tokenize_morphy(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание отформатированных наборов данных с помощью Snowball, Lancaster, PyMorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Формирование наборов данных\n",
    "df_morphy = pd.DataFrame({'text':[tokenize_morphy(sample) for sample in data['premise']]})\n",
    "df_snowball = pd.DataFrame({'text':[tokenize_snowball(sample) for sample in data['premise']]})\n",
    "df_lancaster = pd.DataFrame({'text':[tokenize_lancaster(sample) for sample in data['premise']]})\n",
    "#Очистка от пустот\n",
    "df_lancaster = df_lancaster.dropna()\n",
    "df_morphy = df_morphy.dropna()\n",
    "df_snowball = df_snowball.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для векторизации текста с использованием словаря Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я формирования словаря\n",
    "def vectorize(doc):\n",
    "    features = defaultdict(int)\n",
    "    for token in doc:\n",
    "        features[token] += 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#формирование словаря со всеми словами\n",
    "def make_dictionary_words(df):\n",
    "    dictionary_whole_words = defaultdict(int)\n",
    "    for doc in df['text']:\n",
    "        for token in doc:\n",
    "            dictionary_whole_words[token] += 1\n",
    "    return dictionary_whole_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я конвертации предложения в вектор на основе общего словаря\n",
    "def sentence_to_vector(sentence, dictionary_whole_words):\n",
    "    sentence = np.array(sentence)\n",
    "    vector = np.zeros(len(dictionary_whole_words))\n",
    "    dict_values = np.array(list(dictionary_whole_words.values()))\n",
    "    dict_keys = np.array(list(dictionary_whole_words.keys()))\n",
    "    sorter = np.argsort(dict_keys)\n",
    "    for idx in sorter[np.searchsorted(dict_keys, sentence, sorter = sorter)]:\n",
    "        vector[idx] = dict_values[idx]\n",
    "    return vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования векторизации с помощью словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dict = make_dictionary_words(df_morphy) #общий словарь на основе всего набора данных\n",
    "whole_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 8. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#пример формирования вектора отдельного корпуса текста \n",
    "print(sentence_to_vector(df_morphy['text'][1], whole_dict)[20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизация текста Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[сумма, ущерб, составить, один, тысяча, рубль,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[словечко, скользить, глаз, мой, город, как, с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[разве, сказать, хотеть, выпить, кофе, я, каза...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[зима, показать, свой, характер]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[но, он, благость, оставаться, непросто, жить,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [сумма, ущерб, составить, один, тысяча, рубль,...\n",
       "1  [словечко, скользить, глаз, мой, город, как, с...\n",
       "2  [разве, сказать, хотеть, выпить, кофе, я, каза...\n",
       "3                   [зима, показать, свой, характер]\n",
       "4  [но, он, благость, оставаться, непросто, жить,..."
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_morphy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>авар</th>\n",
       "      <th>аварийн</th>\n",
       "      <th>авиасалон</th>\n",
       "      <th>автомобил</th>\n",
       "      <th>автор</th>\n",
       "      <th>агентств</th>\n",
       "      <th>агрессивн</th>\n",
       "      <th>адвокат</th>\n",
       "      <th>адрес</th>\n",
       "      <th>адск</th>\n",
       "      <th>...</th>\n",
       "      <th>яблон</th>\n",
       "      <th>явк</th>\n",
       "      <th>явля</th>\n",
       "      <th>ядерн</th>\n",
       "      <th>язык</th>\n",
       "      <th>якоб</th>\n",
       "      <th>январ</th>\n",
       "      <th>ярост</th>\n",
       "      <th>ясн</th>\n",
       "      <th>ясност</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 2579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     авар  аварийн  авиасалон  автомобил  автор  агентств  агрессивн  адвокат  \\\n",
       "0       0        0          0          0      0         0          0        0   \n",
       "1       0        0          0          0      0         0          0        0   \n",
       "2       0        0          0          0      0         0          0        0   \n",
       "3       0        0          0          0      0         0          0        0   \n",
       "4       0        0          0          0      0         0          0        0   \n",
       "..    ...      ...        ...        ...    ...       ...        ...      ...   \n",
       "433     0        0          0          0      0         0          0        0   \n",
       "434     0        0          0          0      0         0          0        0   \n",
       "435     0        0          0          0      0         0          0        0   \n",
       "436     0        0          0          0      0         0          0        0   \n",
       "437     0        0          0          0      0         0          0        0   \n",
       "\n",
       "     адрес  адск  ...  яблон  явк  явля  ядерн  язык  якоб  январ  ярост  ясн  \\\n",
       "0        0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "1        0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "2        0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "3        0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "4        0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "..     ...   ...  ...    ...  ...   ...    ...   ...   ...    ...    ...  ...   \n",
       "433      0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "434      0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "435      0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "436      0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "437      0     0  ...      0    0     0      0     0     0      0      0    0   \n",
       "\n",
       "     ясност  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "433       0  \n",
       "434       0  \n",
       "435       0  \n",
       "436       0  \n",
       "437       0  \n",
       "\n",
       "[438 rows x 2579 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW sklearn finally version\n",
    "vec = CountVectorizer()\n",
    "corpus = []\n",
    "for sent in df_snowball['text']:\n",
    "    corpus.append(' '.join(sent))\n",
    "X = vec.fit_transform(corpus)\n",
    "pd.DataFrame(X.toarray(), columns=sorted(vec.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>авар</th>\n",
       "      <th>аварийн</th>\n",
       "      <th>авиасалон</th>\n",
       "      <th>автомобил</th>\n",
       "      <th>автор</th>\n",
       "      <th>агентств</th>\n",
       "      <th>агрессивн</th>\n",
       "      <th>адвокат</th>\n",
       "      <th>адрес</th>\n",
       "      <th>адск</th>\n",
       "      <th>...</th>\n",
       "      <th>яблон</th>\n",
       "      <th>явк</th>\n",
       "      <th>явля</th>\n",
       "      <th>ядерн</th>\n",
       "      <th>язык</th>\n",
       "      <th>якоб</th>\n",
       "      <th>январ</th>\n",
       "      <th>ярост</th>\n",
       "      <th>ясн</th>\n",
       "      <th>ясност</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 2579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     авар  аварийн  авиасалон  автомобил  автор  агентств  агрессивн  адвокат  \\\n",
       "0     0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "1     0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "2     0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "3     0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "4     0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "..    ...      ...        ...        ...    ...       ...        ...      ...   \n",
       "433   0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "434   0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "435   0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "436   0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "437   0.0      0.0        0.0        0.0    0.0       0.0        0.0      0.0   \n",
       "\n",
       "     адрес  адск  ...  яблон  явк  явля  ядерн  язык  якоб  январ  ярост  ясн  \\\n",
       "0      0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "1      0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "2      0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "3      0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "4      0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "..     ...   ...  ...    ...  ...   ...    ...   ...   ...    ...    ...  ...   \n",
       "433    0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "434    0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "435    0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "436    0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "437    0.0   0.0  ...    0.0  0.0   0.0    0.0   0.0   0.0    0.0    0.0  0.0   \n",
       "\n",
       "     ясност  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "433     0.0  \n",
       "434     0.0  \n",
       "435     0.0  \n",
       "436     0.0  \n",
       "437     0.0  \n",
       "\n",
       "[438 rows x 2579 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(corpus)\n",
    "pd.DataFrame(X.toarray(), columns=sorted(vec.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['авар' 'аварийн' 'авиасалон' ... 'ярост' 'ясн' 'ясност']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morphy_copy = df_morphy['text'].apply(lambda col: ' '.join(col)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2156)\t1\n",
      "  (0, 2388)\t1\n",
      "  (0, 2049)\t1\n",
      "  (0, 1213)\t1\n",
      "  (0, 2271)\t1\n",
      "  (0, 1870)\t1\n",
      "  (0, 2370)\t1\n",
      "  (0, 924)\t1\n",
      "  (0, 273)\t1\n",
      "  (0, 381)\t1\n",
      "  (0, 798)\t1\n",
      "  (0, 2361)\t1\n",
      "  (0, 863)\t1\n",
      "  (0, 1232)\t1\n",
      "  (0, 1223)\t1\n",
      "  (0, 923)\t1\n",
      "  (0, 531)\t1\n",
      "  (0, 1799)\t1\n",
      "  (0, 2147)\t1\n",
      "  (0, 1450)\t1\n",
      "  (1, 1977)\t1\n",
      "  (1, 1954)\t1\n",
      "  (1, 330)\t1\n",
      "  (1, 949)\t1\n",
      "  (1, 353)\t1\n",
      "  :\t:\n",
      "  (434, 163)\t1\n",
      "  (434, 338)\t2\n",
      "  (434, 981)\t1\n",
      "  (434, 968)\t1\n",
      "  (434, 1352)\t1\n",
      "  (434, 255)\t2\n",
      "  (434, 213)\t1\n",
      "  (434, 24)\t1\n",
      "  (434, 2472)\t1\n",
      "  (434, 815)\t1\n",
      "  (434, 763)\t1\n",
      "  (435, 386)\t1\n",
      "  (435, 338)\t1\n",
      "  (435, 968)\t1\n",
      "  (435, 2270)\t1\n",
      "  (435, 2174)\t1\n",
      "  (435, 589)\t1\n",
      "  (435, 638)\t1\n",
      "  (436, 1944)\t1\n",
      "  (436, 921)\t1\n",
      "  (436, 2189)\t1\n",
      "  (436, 2082)\t1\n",
      "  (436, 2203)\t1\n",
      "  (436, 2332)\t1\n",
      "  (436, 19)\t1\n"
     ]
    }
   ],
   "source": [
    "corpus = df_morphy_copy\n",
    "vectors = vectorizer.fit_transform(corpus)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизация Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc for doc in df_morphy['text']]\n",
    "id2word = gensim.corpora.Dictionary(corpus)\n",
    "vectors = [id2word.doc2bow(doc) for doc in corpus]\n",
    "for v in vectors:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_series = df_morphy['text']\n",
    "allsentences = []\n",
    "for sent in text_series:\n",
    "    allsentences.append(' '.join(sent))\n",
    "allsentences = pd.Series(allsentences)\n",
    "print(allsentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение мульт регрессии на классификацию жанра текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
