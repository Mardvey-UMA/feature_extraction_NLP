{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import sklearn\n",
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NitghtWay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NitghtWay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "rus = \"russian\"\n",
    "sw = stopwords.words(rus)\n",
    "morph = MorphAnalyzer()\n",
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(language=rus)\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для вывода текстовых данных в удобном формате\n",
    "def print_table(array):\n",
    "    table_width = 5\n",
    "    for i in range(0, len(array), table_width):\n",
    "        row = array[i:i + table_width]\n",
    "        formatted_row = \" \".join([\"{:<10}\".format(str(elem)) for elem in row])\n",
    "        print(formatted_row)\n",
    "#ф-я для удаления символов пунктуации\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([ch for ch in text if ch not in \n",
    "    string.punctuation])\n",
    "#ф-я для удаления чисел\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text]) \n",
    "#ф-я для удаления последовательностей\n",
    "def remove_patterns(text):\n",
    "    text = re.sub(patterns, ' ', text)\n",
    "    return text\n",
    "#ф-я для удаления не буквенных символов\n",
    "def remove_notalpha(text):\n",
    "    return ''.join(i if i.isalpha() else ' ' for i in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я токенизации с использованием Snowball\n",
    "def tokenize_snowball(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_patterns(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(snowball.stem(w))\n",
    "            \n",
    "    return ' '.join(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я токенизации с использованием Lancaster\n",
    "def tokenize_lancaster(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_patterns(text)\n",
    "    text = remove_punctuation(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(lancaster.stem(w))\n",
    "    return ' '.join(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я токенизации с помощью PyMorphy2\n",
    "def tokenize_morphy(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_patterns(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            all_words.append(morph.normal_forms(w)[0])\n",
    "    if len(all_words) > 2:\n",
    "        return ' '.join(all_words)\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:\\\\course_work\\\\feature_extraction_NLP\\\\data\\\\test_ds1\\\\train.jsonl'\n",
    "val_path = 'C:\\\\course_work\\\\feature_extraction_NLP\\\\data\\\\test_ds1\\\\val.jsonl'\n",
    "train_data = pd.read_json(train_path, lines=True)\n",
    "val_data = pd.read_json(val_path, lines=True)\n",
    "df = pd.concat([train_data, val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096, 8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>label</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>verb</th>\n",
       "      <th>negation</th>\n",
       "      <th>genre</th>\n",
       "      <th>idx</th>\n",
       "      <th>no_negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сумма ущерба составила одну тысячу рублей. Уто...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Ранее местный житель совершал подобное правона...</td>\n",
       "      <td>судить</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>kp</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Перебрасываясь словечками, они скользят глазам...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>Они что-то понимают</td>\n",
       "      <td>смотреть</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>— Разве что, — сказала она, — мы хотим где-ниб...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Это “ Таганская ”, а не “ Тульская ”.</td>\n",
       "      <td>понять</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зима, наконец, показала свой характер.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>У зимы есть свой характер.</td>\n",
       "      <td>показать</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>kp</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Гуманность Бога подобным сценарием не предпола...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>Это должно быть просто.</td>\n",
       "      <td>сказать</td>\n",
       "      <td>no_negation</td>\n",
       "      <td>fiction</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise          label  \\\n",
       "0  Сумма ущерба составила одну тысячу рублей. Уто...     entailment   \n",
       "1  Перебрасываясь словечками, они скользят глазам...  contradiction   \n",
       "2  — Разве что, — сказала она, — мы хотим где-ниб...        neutral   \n",
       "3             Зима, наконец, показала свой характер.  contradiction   \n",
       "4  Гуманность Бога подобным сценарием не предпола...  contradiction   \n",
       "\n",
       "                                          hypothesis      verb     negation  \\\n",
       "0  Ранее местный житель совершал подобное правона...    судить  no_negation   \n",
       "1                                Они что-то понимают  смотреть  no_negation   \n",
       "2              Это “ Таганская ”, а не “ Тульская ”.    понять  no_negation   \n",
       "3                         У зимы есть свой характер.  показать  no_negation   \n",
       "4                            Это должно быть просто.   сказать  no_negation   \n",
       "\n",
       "     genre  idx no_negation  \n",
       "0       kp    0         NaN  \n",
       "1  fiction    1         NaN  \n",
       "2  fiction    2         NaN  \n",
       "3       kp    3         NaN  \n",
       "4  fiction    4         NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['label', 'hypothesis', 'verb','negation'\n",
    ",'idx','no_negation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сумма ущерба составила одну тысячу рублей. Уто...</td>\n",
       "      <td>kp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Перебрасываясь словечками, они скользят глазам...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>— Разве что, — сказала она, — мы хотим где-ниб...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зима, наконец, показала свой характер.</td>\n",
       "      <td>kp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Гуманность Бога подобным сценарием не предпола...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Кому они нужны? Ее нужно забрать в сумасшедший...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>– А я вас все равно люблю, – скажу я. – Но как...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>По ее словам, она помнит лишь, что собиралась ...</td>\n",
       "      <td>kp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Допросив гостя, следователи восстановили карти...</td>\n",
       "      <td>kp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Это стало для меня откровением, я понял, что е...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               premise    genre\n",
       "0    Сумма ущерба составила одну тысячу рублей. Уто...       kp\n",
       "1    Перебрасываясь словечками, они скользят глазам...  fiction\n",
       "2    — Разве что, — сказала она, — мы хотим где-ниб...  fiction\n",
       "3               Зима, наконец, показала свой характер.       kp\n",
       "4    Гуманность Бога подобным сценарием не предпола...  fiction\n",
       "..                                                 ...      ...\n",
       "215  Кому они нужны? Ее нужно забрать в сумасшедший...  fiction\n",
       "216  – А я вас все равно люблю, – скажу я. – Но как...  fiction\n",
       "217  По ее словам, она помнит лишь, что собиралась ...       kp\n",
       "218  Допросив гостя, следователи восстановили карти...       kp\n",
       "219  Это стало для меня откровением, я понял, что е...  fiction\n",
       "\n",
       "[1096 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сумма ущерба составила одну тысячу рублей. Уто...</td>\n",
       "      <td>kp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Перебрасываясь словечками, они скользят глазам...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>— Разве что, — сказала она, — мы хотим где-ниб...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зима, наконец, показала свой характер.</td>\n",
       "      <td>kp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Гуманность Бога подобным сценарием не предпола...</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise    genre\n",
       "0  Сумма ущерба составила одну тысячу рублей. Уто...       kp\n",
       "1  Перебрасываясь словечками, они скользят глазам...  fiction\n",
       "2  — Разве что, — сказала она, — мы хотим где-ниб...  fiction\n",
       "3             Зима, наконец, показала свой характер.       kp\n",
       "4  Гуманность Бога подобным сценарием не предпола...  fiction"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'] = df['genre'].replace('kp', 'interfax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivot_table = df.groupby('genre').size()\n",
    "pivot_table.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({'genre':[str(genre) for genre in df['genre']]})\n",
    "#Формирование наборов данных\n",
    "df_morphy = pd.DataFrame({'text':[tokenize_morphy(sample) \n",
    "for sample in df['premise']]})\n",
    "df_snowball = pd.DataFrame({'text':[tokenize_snowball(sample) \n",
    "for sample in df['premise']]})\n",
    "df_lancaster = pd.DataFrame({'text':[tokenize_lancaster(sample) \n",
    "for sample in df['premise']]})\n",
    "#Очистка от пустот\n",
    "X1 = df_lancaster.dropna()\n",
    "X2 = df_morphy.dropna()\n",
    "X3 = df_snowball.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interfax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interfax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      genre\n",
       "0  interfax\n",
       "1   fiction\n",
       "2   fiction\n",
       "3  interfax\n",
       "4   fiction"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 1)\n",
      "(1096, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X2\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.text, Y.genre, test_size = 0.1, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     fiction       0.95      0.88      0.91        64\n",
      "    interfax       0.84      0.93      0.89        46\n",
      "\n",
      "    accuracy                           0.90       110\n",
      "   macro avg       0.90      0.90      0.90       110\n",
      "weighted avg       0.90      0.90      0.90       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BOW\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "bow = vec.fit_transform(x_train)  # bow — bag of words (мешок слов)\n",
    "bow_test = vec.transform(x_test)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow = scaler.fit_transform(bow)\n",
    "bow_test = scaler.transform(bow_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(bow_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     fiction       0.93      0.89      0.91        64\n",
      "    interfax       0.86      0.91      0.88        46\n",
      "\n",
      "    accuracy                           0.90       110\n",
      "   macro avg       0.90      0.90      0.90       110\n",
      "weighted avg       0.90      0.90      0.90       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tf-idf\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "vec_train = vec.fit_transform(x_train)\n",
    "vec_test = vec.transform(x_test)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "vec_train = scaler.fit_transform(vec_train)\n",
    "vec_test = scaler.transform(vec_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=300, random_state=42)\n",
    "clf.fit(vec_train, y_train)\n",
    "pred_tfidf = clf.predict(vec_test)\n",
    "print(classification_report(y_test, pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'подозревать'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_vocab = {value: key for key, value in vec.vocabulary_.items()}\n",
    "reverse_vocab[np.argmax(clf.coef_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ посимвольный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:\\\\course_work\\\\feature_extraction_NLP\\\\data\\\\test_ds1\\\\train.jsonl'\n",
    "val_path = 'C:\\\\course_work\\\\feature_extraction_NLP\\\\data\\\\test_ds1\\\\val.jsonl'\n",
    "train_data = pd.read_json(train_path, lines=True)\n",
    "val_data = pd.read_json(val_path, lines=True)\n",
    "df = pd.concat([train_data, val_data])\n",
    "df = df.drop(['label', 'hypothesis', 'verb','negation'\n",
    ",'idx','no_negation'], axis=1)\n",
    "df['genre'] = df['genre'].replace('kp', 'interfax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({'genre':[str(genre) for genre in df['genre']]})\n",
    "X = pd.DataFrame({'text': [text for text in df['premise']]})\n",
    "x_train, x_test, y_train, y_test = train_test_split(X.text, Y.genre, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600    и человек вроде бы хороший мягкий артист немно...\n",
       "76     каждый сам за себя жить вместе а с ум сходить ...\n",
       "591    по он слово по мера укрепление партийный струк...\n",
       "321    после стать я думать что говорить мама когда о...\n",
       "487    за умышленный причинение тяжкий вред здоровье ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     fiction       0.87      0.91      0.89       137\n",
      "    interfax       0.91      0.86      0.88       137\n",
      "\n",
      "    accuracy                           0.89       274\n",
      "   macro avg       0.89      0.89      0.89       274\n",
      "weighted avg       0.89      0.89      0.89       274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), analyzer=\"char\")\n",
    "bow = vec.fit_transform(x_train)\n",
    "bow_test = vec.transform(x_test)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow = scaler.fit_transform(bow)\n",
    "bow_test = scaler.transform(bow_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(bow_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_vocab = {value: key for key, value in vec.vocabulary_.items()}\n",
    "reverse_vocab[np.argmax(clf.coef_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование BERT, W2V, улучшение мешка слов и tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(876,)\n",
      "(220,)\n"
     ]
    }
   ],
   "source": [
    "X = X2 \n",
    "x_train, x_test, y_train, y_test = train_test_split(X.text, Y.genre, test_size = 0.2, random_state = 45)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(min_df=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(min_df=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(min_df=5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 5, max_df = 1.0, ngram_range = (1, 1))\n",
    "tfidf.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 679), (220, 679))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = tfidf.transform(x_train)\n",
    "Xtest = tfidf.transform(x_test)\n",
    "\n",
    "Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(Xtrain, y_train)\n",
    "\n",
    "lr_train_pred = lr_clf.predict(Xtrain)\n",
    "lr_test_pred = lr_clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9257990867579908, 0.8818181818181818)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_train, lr_train_pred), accuracy_score(y_test, lr_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(min_df=5, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(min_df=5, ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(min_df=5, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, max_df=1.0, ngram_range=(1, 2))\n",
    "tfidf.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((876, 911), (220, 911))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = tfidf.transform(x_train)\n",
    "Xtest = tfidf.transform(x_test)\n",
    "\n",
    "Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.932648401826484, 0.8863636363636364)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(Xtrain, y_train)\n",
    "\n",
    "lr_train_pred = lr_clf.predict(Xtrain)\n",
    "lr_test_pred = lr_clf.predict(Xtest)\n",
    "\n",
    "accuracy_score(y_train, lr_train_pred), accuracy_score(y_test, lr_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767,) <class 'pandas.core.series.Series'>\n",
      "(329,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X = X2 #использование \n",
    "X_train, X_test, y_train, y_test = train_test_split(X.text, Y.genre, test_size = 0.3, random_state = 45)\n",
    "print(X_train.shape, type(X_train))\n",
    "print(X_test.shape, type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281     я посыпать голова пепел жениться хоть на стару...\n",
       "63      мы по прежний исходить из тот что быть факт на...\n",
       "5       для мама праздник быть как обычный день она ко...\n",
       "256     снова появиться но уже с пепельница мочь челов...\n",
       "1054    сосед по камера жестоко избить мигрант в ход н...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\course_work\\feature_extraction_NLP\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#X_train[91]\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m sent \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(sent)\n",
      "File \u001b[1;32mc:\\course_work\\feature_extraction_NLP\\.conda\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\course_work\\feature_extraction_NLP\\.conda\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\course_work\\feature_extraction_NLP\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#X_train[91]\n",
    "sent = [row.split() for row in X_train['text']]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27078, 625650)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN = 100\n",
    "model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=HIDDEN,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=2)\n",
    "model.build_vocab(sent, progress_per=10000)\n",
    "model.train(sent, total_examples=model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#счет последнего вектора текста\n",
    "def get_mean_w2v_vector(sentence):\n",
    "    Sum = 0\n",
    "    Count = 0\n",
    "\n",
    "    try:\n",
    "      words = sentence.split()\n",
    "    except TypeError:\n",
    "      words = []\n",
    "\n",
    "    for w in words:\n",
    "        if w in model.wv:\n",
    "            Sum += model.wv[w]\n",
    "            # Sum += glove_vectors[w]\n",
    "            Count += 1\n",
    "\n",
    "    if Count == 0:\n",
    "        return 0\n",
    "\n",
    "    return Sum / Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewCols = ['col'+str(i) for i in range(HIDDEN)]\n",
    "\n",
    "X_train['vectors'] = X_train['text'].map(get_mean_w2v_vector)\n",
    "X_test['vectors'] = X_test['text'].map(get_mean_w2v_vector)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10860\\535633417.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mIdxTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vectors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mIdxTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\course_work\\feature_extraction_NLP\\.conda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "IdxTrain = []\n",
    "\n",
    "for ix, row in X_train.iterrows():\n",
    "    if not isinstance(row['vectors'],np.ndarray):\n",
    "        IdxTrain.append(ix)\n",
    "\n",
    "IdxTest = []\n",
    "\n",
    "for ix, row in X_test.iterrows():\n",
    "    if not isinstance(row['vectors'],np.ndarray):\n",
    "        IdxTest.append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(index=IdxTrain, inplace=True)\n",
    "X_test.drop(index=IdxTest, inplace=True)\n",
    "\n",
    "y_train = y_train.drop(index=IdxTrain)\n",
    "y_test = y_test.drop(index=IdxTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[NewCols] = pd.DataFrame(X_train['vectors'].tolist(), index=X_train.index)\n",
    "X_test[NewCols] = pd.DataFrame(X_test['vectors'].tolist(), index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([0,'vectors'], axis=1, inplace=True)\n",
    "X_test.drop([0,'vectors'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_train_pred = lr_clf.predict(X_train)\n",
    "lr_test_pred = lr_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_train, lr_train_pred), accuracy_score(y_test, lr_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
