{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import sklearn\n",
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "from gensim.models import Word2Vec\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim.downloader\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NitghtWay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NitghtWay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "patterns = \"[A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "rus = \"russian\"\n",
    "sw = stopwords.words(rus)\n",
    "morph = MorphAnalyzer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(language=rus)\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ф-я для вывода текстовых данных в удобном формате\n",
    "def print_table(array):\n",
    "    table_width = 5\n",
    "    for i in range(0, len(array), table_width):\n",
    "        row = array[i:i + table_width]\n",
    "        formatted_row = \" \".join([\"{:<10}\".format(str(elem)) for elem in row])\n",
    "        print(formatted_row)\n",
    "#ф-я для удаления символов пунктуации\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([ch for ch in text if ch not in \n",
    "    string.punctuation])\n",
    "#ф-я для удаления чисел\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text]) \n",
    "#ф-я для удаления последовательностей\n",
    "def remove_patterns(text):\n",
    "    text = re.sub(patterns, ' ', text)\n",
    "    return text\n",
    "#ф-я для удаления не буквенных символов\n",
    "def remove_notalpha(text):\n",
    "    return ''.join(i if i.isalpha() else ' ' for i in text)\n",
    "#ф-я токенизации с использованием Snowball\n",
    "def tokenize_snowball(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_patterns(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(snowball.stem(w))\n",
    "            \n",
    "    return ' '.join(all_words)\n",
    "#ф-я токенизации с использованием Lancaster\n",
    "def tokenize_lancaster(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_patterns(text)\n",
    "    text = remove_punctuation(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            if w in sw or len(w) >= 11:\n",
    "                continue\n",
    "            else:\n",
    "                all_words.append(lancaster.stem(w))\n",
    "    return ' '.join(all_words)\n",
    "#ф-я токенизации с помощью PyMorphy2\n",
    "def tokenize_morphy(text):\n",
    "    text = remove_notalpha(text)\n",
    "    text = remove_patterns(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    sentences = sent_tokenize(text, language=rus)\n",
    "    all_words = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent, language=rus)\n",
    "        for w in words:\n",
    "            all_words.append(morph.normal_forms(w)[0])\n",
    "    if len(all_words) > 2:\n",
    "        return ' '.join(all_words)\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
