{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иморт библиотек и заранее подготовленных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import import_librares # ноутбук с импортом библиотек\n",
    "import func # ноутбук с функциями\n",
    "import rus_ds_data # ноутбук с загрузкой и предварительной обрабткой русского датасета\n",
    "from ipynb.fs.full.func import tokenize_morphy, tokenize_lancaster, tokenize_snowball\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rus_ds_data import\\\n",
    "    df, Y, df_morphy, df_snowball, df_lancaster\\\n",
    "    , X1, X2, X3, batch1, batch2, batch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_librares import CountVectorizer, TfidfVectorizer, plt, train_test_split\\\n",
    ",LogisticRegression, classification_report, roc_auc_score, MaxAbsScaler, GridSearchCV\\\n",
    ",cross_val_score, ppb, Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разбиение на данные\n",
    "x_train, x_test, y_train, y_test = train_test_split(batch2['text'], batch2['genre'], test_size = 0.1, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     fiction       0.86      0.91      0.88        53\n",
      "    interfax       0.91      0.86      0.88        57\n",
      "\n",
      "    accuracy                           0.88       110\n",
      "   macro avg       0.88      0.88      0.88       110\n",
      "weighted avg       0.88      0.88      0.88       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# объявляем экземпляр класса CountVectorizer\n",
    "# используем униграммы, то есть каждое слово отдельно\n",
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "# формируем мешок слов на тренировочных данных, используем fit_transform\n",
    "# для обучения векторизатора на тренировочных данных\n",
    "bow = vec.fit_transform(x_train) \n",
    "# преобразуем тестовые данные в числовые векторы используя обученный векторизатор\n",
    "bow_test = vec.transform(x_test)\n",
    "# Используем MaxAbsScaler для приведения всех признаков к одинаковому масштабу\n",
    "scaler = MaxAbsScaler() \n",
    "# обучаем масштабировщик на тренирвочных данных и преобразуем\n",
    "bow = scaler.fit_transform(bow) \n",
    "# применяем обученный масштабировщик к тестовым данным\n",
    "bow_test = scaler.transform(bow_test) \n",
    "\n",
    "# обучаем логистическую регрессию на масштабированных тренировочных данных\n",
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "\n",
    "# получаем предсказание на тестовых данных\n",
    "pred = clf.predict(bow_test)\n",
    "\n",
    "# отчет о классификации с использованием разилчных метрик\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
