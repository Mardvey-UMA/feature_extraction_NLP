# Выделение признаков из текстовых данных

## План курсовой работы:

1. Введение в задачу выделения признаков из текстовых данных.
2. Изучение и предобработка исходных текстовых данных.
3. Применение методов токенизации и векторизации текста.
4. Разработка и обучение моделей машинного обучения для выделения признаков.
5. Оценка результатов и анализ полученных признаков.
6. Выводы и заключение.

## Используемые технологии:

- Python
- scikit-learn (sklearn)
- PyTorch (torch)
- NumPy
- pymorphy2

## Введение:

Современные исследования говорят о том, что средняя веб-страница может содержать объем текста в среднем на 6.5 печатных страниц. Приняв во внимание этот факт для распечатки всех текстовых данных интернете потребуется примерно 310 миллиардов листов. В связи с этим остро встает вопрос анализа текстовых данных, речь идет не только о технической литературе, статьях, но и рядовых данных, таких как посты в социальных сетях, реклама и тому подобное. Важно уметь правильно интерпретировать такие данные, уметь выявлять главное, а имея такие объемы невозможно обойтись без автоматизации.
Эти данные можно использовать не только как полезные материалы для извлечения информации, но и как примеры для обучения алгоритмов машинного обучения для решения различных задач, например, классификации, оценки тональности, выявления спам-почты. Также не стоит забывать о глубоком обучении, которое помогает в обучении языковых моделей для чат-ботов, голосовых помощников и т.д. Одной из основ машинного обучения является правило “мусор” на входе “мусор” на выходе, то есть на сколько совершенные алгоритмы и методы мы бы не использовали, если исходные данные имеют шумы, неточности, аномалии, пробелы, то и модель, обученная на таких данных будет работать не корректно.


## Промежуточные результаты:
### Мешок слов
|  | REG|	SVC|	DTC|	RFC|	GBC|	ABC|	KNC|
|----|-----|-----|-----|----|------|-----|---|
|ACC|	0.854545|	0.795455|	0.722727|	0.795455|	0.790909|	0.768182|	0.6|
|PREC|	0.818898|	0.732877|	0.725191|	0.739726|	0.731034|	0.715278|	0.563452|
|REC|	0.920354|	0.946903|	0.849558|	0.946903|	0.938053|	0.911504|	0.982301|
|F1|	0.866667|	0.826255|	0.811475|	0.834646|	0.821705|	0.801556|	0.716129|

### Tf-idf
| |REG|	SVC|	DTC|	RFC|	GBC|	ABC|	KNC|
|----|-----|-----|-----|----|------|-----|---|
|ACC|	0.840909|	0.836364|	0.763636|	0.822727|	0.786364|	0.713636|	0.713636|
|PREC|	0.795455|	0.793893|	0.763158|	0.776119|	0.736111|	0.668919|	0.647059|
|REC|	0.929204|	0.920354|	0.778761|	0.911504|	0.938053|	0.876106|	0.973451|
|F1|	0.857143|	0.852459|	0.756522|	0.830645|	0.824903|	0.758621|	0.777385|
### Word2Vec
|   |REG|	SVC|	DTC|	RFC|	GBC|	ABC|	KNC|
|----|-----|-----|-----|----|------|-----|---|
|ACC|	0.518182|	0.513636|	0.722727|	0.677273|	0.677273|	0.65|	0.654545|
|PREC|	0.515982|	0.513636|	0.727273|	0.657534|	0.661654|	0.632353|	0.617834|
|REC|	1.0|	1.0|	0.743363|	0.867257|	0.778761|	0.761062|	0.858407|
|F1|	0.680723|	0.678679|	0.709402|	0.747082|	0.710204|	0.690763|	0.718519|
### FastText
|    |REG|	SVC|	DTC|	RFC|	GBC|	ABC|	KNC|
|----|-----|-----|-----|----|------|-----|---|
|ACC|	0.927273|	0.931818|	0.927273|	0.95|	0.936364|	0.931818|	0.945455|
|PREC|	0.9|	0.91453|	0.929204|	0.931624|	0.900826|	0.91453|	0.938596|
|REC|	0.964286|	0.955357|	0.9375|	0.973214|	0.973214|	0.955357|	0.955357|
|F1|	0.931034|	0.934498|	0.921053|	0.947826|	0.935622|	0.934498|	0.946903|